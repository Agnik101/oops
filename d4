import numpy as np
import pandas as pd
import matplotlib.pyplot as plt
import seaborn as sns
from sklearn.model_selection import train_test_split
from sklearn.linear_model import LinearRegression
from sklearn.metrics import mean_squared_error, r2_score
from statsmodels.stats.outliers_influence import variance_inflation_factor
from sklearn.preprocessing import StandardScaler

data=pd.read_csv("advertising.csv")
data.head()

data.isnull().sum()

data.describe()

y=data['Sales']
x=data[['TV']]

X_train, X_test, y_train,y_test = train_test_split(x,y,test_size=0.2, random_state=42)
model=LinearRegression()
model.fit(X_train,y_train)


X_train.shape

y_pred=model.predict(X_test)
X_sort=np.sort(x,axis=0)
y_pred_line=model.predict(X_sort)

print("Intercept:",model.intercept_)
print("Slope:",model.coef_[0])

plt.scatter(X_train,y_train,color='yellow',label='Training data')
plt.scatter(X_test,y_test,color='red',label='Test data')
plt.plot(X_sort,y_pred_line,color='green',linewidth=2,label='Regression line')
plt.xlabel("X (TV)")
plt.ylabel("y (Sales)")
plt.legend()
plt.title("Simple linear regression")
plt.show()


r2=r2_score(y_test,y_pred)
mse=mean_squared_error(y_test,y_pred)
print("R^2 score: ",r2)
print("Mean squared error:",mse)



#multiple linear reg
X2=data[['TV', 'Radio','Newspaper']]
y2=data['Sales']


X_train2, X_test2, y_train2,y_test2 = train_test_split(X2,y2,test_size=0.2, random_state=42)
model=LinearRegression()
model.fit(X_train2,y_train2)

y_pred2 = model.predict(X_test2)

r2_2 = r2_score(y_test2, y_pred2)
mse_2 = mean_squared_error(y_test2, y_pred2)

print("\nMultiple Linear Regression")
print("R² Score:", r2_2)
print("MSE:", mse_2)

print("Intercept (b0):", model.intercept_)
tv_coef, radio_coef, newspaper_coef = model.coef_
print(f"TV Coefficient: {tv_coef}")
print(f"Radio Coefficient: {radio_coef}")
print(f"Newspaper Coefficient: {newspaper_coef}")


vif_data = pd.DataFrame()
vif_data["Feature"] = X.columns
vif_data["VIF"] = [variance_inflation_factor(X2.values, i) for i in range(len(X2.columns))]

print("\nVariance Inflation Factor (VIF):")
print(vif_data)


#2. car price dataset
data = pd.read_csv('Car Price.csv')
X = data[['Year', 'KM_Driven', 'Transmission', 'Fuel']]
y = data['Selling_Price']
data.head()


X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)

scaler = StandardScaler()
X_train = scaler.fit_transform(X_train)
X_test = scaler.transform(X_test)


variances = np.var(X_train, axis=0)
feature_names = X.columns
high_variance_feature = feature_names[np.argmax(variances)]
low_variance_feature = feature_names[np.argmin(variances)]

print(f"Feature with highest variance: {high_variance_feature}")
print(f"Feature with lowest variance: {low_variance_feature}")



def initialize_weights(X):
    return np.zeros(X.shape[1])

def compute_gradient(X, y, y_pred):
    return -2 * X.T.dot(y - y_pred) / len(y)

def gradient_descent(X, y, learning_rate=0.01, iterations=1000):
    W = initialize_weights(X)
    
    loss_history = []
    
    for i in range(iterations):
        y_pred = X.dot(W)
        
        gradient = compute_gradient(X, y, y_pred)
        
        W = W - learning_rate * gradient
        
        loss = np.mean((y - y_pred) ** 2)
        loss_history.append(loss)
        
        if i % 100 == 0:
            print(f"Iteration {i}, Loss: {loss}")
    
    return W, loss_history




weights, loss_history = gradient_descent(X_train, y_train, learning_rate=0.01, iterations=1000)


plt.plot(loss_history)
plt.xlabel("Iterations")
plt.ylabel("Loss")
plt.title("Convergence of Gradient Descent")
plt.show()


y_train_pred = X_train.dot(weights)
y_test_pred = X_test.dot(weights)



plt.scatter(y_test, y_test_pred)
plt.xlabel("Actual Prices")
plt.ylabel("Predicted Prices")
plt.title("Actual vs Predicted Car Prices")
plt.show()


mse = mean_squared_error(y_test, y_test_pred)
r2 = r2_score(y_test, y_test_pred)

print(f"Mean Squared Error (MSE): {mse}")
print(f"R-squared (R²): {r2}")
